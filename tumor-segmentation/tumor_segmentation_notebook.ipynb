{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a386d094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04d92b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TumorSegmentationDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Tumor segmentation dataset over controls and patients.\n",
    "\n",
    "    Directory layout expected under data_root_dir_path:\n",
    "    - controls/imgs/*.png\n",
    "    - patients/imgs/*.png\n",
    "    - patients/labels/*.png\n",
    "\n",
    "    Controls have no provided labels, so they are assigned all-zero masks.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_root_dir_path: pathlib.Path):\n",
    "        self.data_root_dir_path = pathlib.Path(data_root_dir_path)\n",
    "\n",
    "        self.controls_img_dir = self.data_root_dir_path / \"controls\" / \"imgs\"\n",
    "        self.patient_img_dir = self.data_root_dir_path / \"patients\" / \"imgs\"\n",
    "        self.patient_label_dir = self.data_root_dir_path / \"patients\" / \"labels\"\n",
    "\n",
    "        for directory in [\n",
    "            self.controls_img_dir,\n",
    "            self.patient_img_dir,\n",
    "            self.patient_label_dir,\n",
    "        ]:\n",
    "            if not directory.exists():\n",
    "                raise FileNotFoundError(f\"Missing directory: {directory}\")\n",
    "\n",
    "        self.samples = self._build_samples()\n",
    "        if not self.samples:\n",
    "            raise RuntimeError(\n",
    "                f\"No PNG files found under {self.data_root_dir_path}\"\n",
    "            )\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_index(stem: str) -> str:\n",
    "        match = re.search(r\"(\\d+)\", stem)\n",
    "        if match is None:\n",
    "            raise ValueError(f\"Could not parse numeric id from: {stem}\")\n",
    "        return match.group(1)\n",
    "\n",
    "    def _build_samples(self):\n",
    "        samples = []\n",
    "\n",
    "        control_image_paths = sorted(self.controls_img_dir.glob(\"*.png\"))\n",
    "        for image_path in control_image_paths:\n",
    "            samples.append(\n",
    "                {\n",
    "                    \"image_path\": image_path,\n",
    "                    \"label_path\": None,\n",
    "                    \"is_control\": True,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        label_path_by_index = {\n",
    "            self._extract_index(label_path.stem): label_path\n",
    "            for label_path in self.patient_label_dir.glob(\"*.png\")\n",
    "        }\n",
    "\n",
    "        patient_image_paths = sorted(self.patient_img_dir.glob(\"*.png\"))\n",
    "        for image_path in patient_image_paths:\n",
    "            sample_index = self._extract_index(image_path.stem)\n",
    "            label_path = label_path_by_index.get(sample_index)\n",
    "            if label_path is None:\n",
    "                raise FileNotFoundError(\n",
    "                    f\"Missing label for patient image: {image_path.name}\"\n",
    "                )\n",
    "            samples.append(\n",
    "                {\n",
    "                    \"image_path\": image_path,\n",
    "                    \"label_path\": label_path,\n",
    "                    \"is_control\": False,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_rgb_image(path: pathlib.Path) -> np.ndarray:\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        return np.asarray(image, dtype=np.uint8)\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_binary_mask(path: pathlib.Path) -> np.ndarray:\n",
    "        label_rgb = Image.open(path).convert(\"RGB\")\n",
    "        label_np = np.asarray(label_rgb, dtype=np.uint8)\n",
    "        # Any non-black pixel is treated as tumor.\n",
    "        return (label_np.max(axis=2) > 0).astype(np.uint8)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        sample = self.samples[index]\n",
    "\n",
    "        image_np = self._load_rgb_image(sample[\"image_path\"])\n",
    "\n",
    "        if sample[\"is_control\"]:\n",
    "            mask_np = np.zeros(image_np.shape[:2], dtype=np.uint8)\n",
    "        else:\n",
    "            mask_np = self._load_binary_mask(sample[\"label_path\"])\n",
    "            if mask_np.shape != image_np.shape[:2]:\n",
    "                raise ValueError(\n",
    "                    f\"Mask/image shape mismatch for {sample['image_path'].name}: \"\n",
    "                    f\"{mask_np.shape} vs {image_np.shape[:2]}\"\n",
    "                )\n",
    "\n",
    "        image_tensor = torch.from_numpy(image_np).permute(2, 0, 1).float() / 255.0\n",
    "        mask_tensor = torch.from_numpy(mask_np).unsqueeze(0).float()\n",
    "\n",
    "        return image_tensor, mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e0d5687",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_segmentation_dataset = TumorSegmentationDataset(data_root_dir_path=pathlib.Path(\"/home/yslcoat/projects/pytorch-training-toolbox/tumor-segmentation/data/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd1ea177",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tumor_segmentation_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa663615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]]]),\n",
       " 'mask': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " 'is_control': True,\n",
       " 'image_path': '/home/yslcoat/projects/pytorch-training-toolbox/tumor-segmentation/data/controls/imgs/control_000.png',\n",
       " 'label_path': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_base_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
